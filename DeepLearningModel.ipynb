{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet=pd.read_csv('college_place.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2966, 8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Stream</th>\n",
       "      <th>Internships</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Hostel</th>\n",
       "      <th>HistoryOfBacklogs</th>\n",
       "      <th>PlacedOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Electronics And Communication</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender                         Stream  Internships  CGPA  Hostel  \\\n",
       "0   22    Male  Electronics And Communication            1     8       1   \n",
       "1   21  Female               Computer Science            0     7       1   \n",
       "2   22  Female         Information Technology            1     6       0   \n",
       "3   21    Male         Information Technology            0     8       0   \n",
       "4   22    Male                     Mechanical            0     8       1   \n",
       "\n",
       "   HistoryOfBacklogs  PlacedOrNot  \n",
       "0                  1            1  \n",
       "1                  1            1  \n",
       "2                  0            1  \n",
       "3                  1            1  \n",
       "4                  0            1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                   int64\n",
       "Gender               object\n",
       "Stream               object\n",
       "Internships           int64\n",
       "CGPA                  int64\n",
       "Hostel                int64\n",
       "HistoryOfBacklogs     int64\n",
       "PlacedOrNot           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet['Gender']=dataSet['Gender'].map({'Male':1,'Female':0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet['Stream'] = dataSet['Stream'].map({'Electronics And Communication': 1,  \n",
    "                                 'Computer Science': 2,  \n",
    "                                'Information Technology': 3,  \n",
    "                                'Mechanical':4,  \n",
    "                                'Electrical':5,  \n",
    "                                'Civil':6})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataSet.iloc[:,0:7]\n",
    "Y=dataSet.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(X)  \n",
    "Y = np.array(Y)  \n",
    "\n",
    "\n",
    "data = np.column_stack((X, Y))  \n",
    "\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "\n",
    "split_ratio = 0.7\n",
    "train_size = int(len(data) * split_ratio)\n",
    "\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "X_train = train_data[:, :-1]  \n",
    "Y_train = train_data[:, -1]  \n",
    "\n",
    "X_test = test_data[:, :-1]    \n",
    "Y_test = test_data[:, -1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu')) \n",
    "\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4797 - loss: 0.7438 - val_accuracy: 0.6461 - val_loss: 0.6659 - learning_rate: 1.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6405 - val_accuracy: 0.7393 - val_loss: 0.6334 - learning_rate: 1.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7038 - loss: 0.5900 - val_accuracy: 0.7798 - val_loss: 0.5903 - learning_rate: 1.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7061 - loss: 0.5726 - val_accuracy: 0.7921 - val_loss: 0.5459 - learning_rate: 1.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.5343 - val_accuracy: 0.8079 - val_loss: 0.5085 - learning_rate: 1.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.5266 - val_accuracy: 0.7921 - val_loss: 0.4863 - learning_rate: 1.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.5271 - val_accuracy: 0.8000 - val_loss: 0.4680 - learning_rate: 1.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7624 - loss: 0.4956 - val_accuracy: 0.7978 - val_loss: 0.4531 - learning_rate: 1.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7634 - loss: 0.4960 - val_accuracy: 0.8079 - val_loss: 0.4404 - learning_rate: 1.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7817 - loss: 0.4655 - val_accuracy: 0.8090 - val_loss: 0.4367 - learning_rate: 1.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.4691 - val_accuracy: 0.8101 - val_loss: 0.4321 - learning_rate: 1.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7824 - loss: 0.4574 - val_accuracy: 0.8180 - val_loss: 0.4200 - learning_rate: 1.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8063 - loss: 0.4361 - val_accuracy: 0.8169 - val_loss: 0.4158 - learning_rate: 1.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.4525 - val_accuracy: 0.8169 - val_loss: 0.4121 - learning_rate: 1.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.4226 - val_accuracy: 0.8202 - val_loss: 0.4088 - learning_rate: 1.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.4454 - val_accuracy: 0.8236 - val_loss: 0.4068 - learning_rate: 1.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8047 - loss: 0.4494 - val_accuracy: 0.8191 - val_loss: 0.4076 - learning_rate: 1.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8261 - loss: 0.4085 - val_accuracy: 0.8225 - val_loss: 0.3999 - learning_rate: 1.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8165 - loss: 0.4231 - val_accuracy: 0.8247 - val_loss: 0.3962 - learning_rate: 1.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.4404 - val_accuracy: 0.8236 - val_loss: 0.3938 - learning_rate: 1.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.4197 - val_accuracy: 0.8225 - val_loss: 0.3922 - learning_rate: 1.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.4096 - val_accuracy: 0.8247 - val_loss: 0.3871 - learning_rate: 1.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.4098 - val_accuracy: 0.8281 - val_loss: 0.3858 - learning_rate: 1.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.3828 - val_accuracy: 0.8270 - val_loss: 0.3813 - learning_rate: 1.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8249 - loss: 0.3953 - val_accuracy: 0.8326 - val_loss: 0.3752 - learning_rate: 1.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8276 - loss: 0.3955 - val_accuracy: 0.8326 - val_loss: 0.3761 - learning_rate: 1.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 0.3691 - val_accuracy: 0.8337 - val_loss: 0.3749 - learning_rate: 1.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.3813 - val_accuracy: 0.8326 - val_loss: 0.3720 - learning_rate: 1.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3940 - val_accuracy: 0.8326 - val_loss: 0.3705 - learning_rate: 1.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.3828 - val_accuracy: 0.8303 - val_loss: 0.3688 - learning_rate: 1.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.3670 - val_accuracy: 0.8337 - val_loss: 0.3672 - learning_rate: 1.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.3886 - val_accuracy: 0.8416 - val_loss: 0.3624 - learning_rate: 1.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.3570 - val_accuracy: 0.8416 - val_loss: 0.3636 - learning_rate: 1.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.3823 - val_accuracy: 0.8337 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3497 - val_accuracy: 0.8337 - val_loss: 0.3637 - learning_rate: 1.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3766 - val_accuracy: 0.8382 - val_loss: 0.3608 - learning_rate: 1.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3742 - val_accuracy: 0.8382 - val_loss: 0.3578 - learning_rate: 1.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.3735 - val_accuracy: 0.8393 - val_loss: 0.3593 - learning_rate: 1.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3549 - val_accuracy: 0.8382 - val_loss: 0.3602 - learning_rate: 1.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.3746 - val_accuracy: 0.8382 - val_loss: 0.3575 - learning_rate: 1.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.3646 - val_accuracy: 0.8371 - val_loss: 0.3558 - learning_rate: 1.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.3576 - val_accuracy: 0.8371 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.3751 - val_accuracy: 0.8494 - val_loss: 0.3454 - learning_rate: 1.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.3653 - val_accuracy: 0.8461 - val_loss: 0.3490 - learning_rate: 1.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3337 - val_accuracy: 0.8472 - val_loss: 0.3441 - learning_rate: 1.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8347 - loss: 0.3645 - val_accuracy: 0.8461 - val_loss: 0.3487 - learning_rate: 1.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.3793 - val_accuracy: 0.8449 - val_loss: 0.3484 - learning_rate: 1.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8488 - loss: 0.3530 - val_accuracy: 0.8461 - val_loss: 0.3421 - learning_rate: 1.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8340 - loss: 0.3717 - val_accuracy: 0.8461 - val_loss: 0.3458 - learning_rate: 1.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.3512 - val_accuracy: 0.8483 - val_loss: 0.3424 - learning_rate: 1.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8540 - loss: 0.3390 - val_accuracy: 0.8483 - val_loss: 0.3440 - learning_rate: 1.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8630 - loss: 0.3252 - val_accuracy: 0.8483 - val_loss: 0.3409 - learning_rate: 1.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8478 - loss: 0.3387 - val_accuracy: 0.8506 - val_loss: 0.3404 - learning_rate: 1.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.3587 - val_accuracy: 0.8483 - val_loss: 0.3426 - learning_rate: 1.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3489 - val_accuracy: 0.8483 - val_loss: 0.3402 - learning_rate: 1.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.3470 - val_accuracy: 0.8483 - val_loss: 0.3407 - learning_rate: 1.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8420 - loss: 0.3559 - val_accuracy: 0.8517 - val_loss: 0.3357 - learning_rate: 1.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.3571 - val_accuracy: 0.8483 - val_loss: 0.3361 - learning_rate: 1.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.3533 - val_accuracy: 0.8517 - val_loss: 0.3338 - learning_rate: 1.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.3634 - val_accuracy: 0.8483 - val_loss: 0.3379 - learning_rate: 1.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3274 - val_accuracy: 0.8483 - val_loss: 0.3384 - learning_rate: 1.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3472 - val_accuracy: 0.8483 - val_loss: 0.3358 - learning_rate: 1.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 0.3304 - val_accuracy: 0.8483 - val_loss: 0.3355 - learning_rate: 1.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8599 - loss: 0.3380 - val_accuracy: 0.8494 - val_loss: 0.3343 - learning_rate: 1.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 0.3321 - val_accuracy: 0.8517 - val_loss: 0.3359 - learning_rate: 1.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 0.3615 - val_accuracy: 0.8562 - val_loss: 0.3325 - learning_rate: 1.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.3691 - val_accuracy: 0.8596 - val_loss: 0.3296 - learning_rate: 1.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.3532 - val_accuracy: 0.8517 - val_loss: 0.3323 - learning_rate: 1.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3423 - val_accuracy: 0.8506 - val_loss: 0.3342 - learning_rate: 1.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.3275 - val_accuracy: 0.8573 - val_loss: 0.3301 - learning_rate: 1.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.3567 - val_accuracy: 0.8596 - val_loss: 0.3306 - learning_rate: 1.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 0.3323 - val_accuracy: 0.8573 - val_loss: 0.3309 - learning_rate: 1.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3132 - val_accuracy: 0.8618 - val_loss: 0.3277 - learning_rate: 1.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8421 - loss: 0.3456 - val_accuracy: 0.8596 - val_loss: 0.3284 - learning_rate: 1.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 0.3291 - val_accuracy: 0.8640 - val_loss: 0.3262 - learning_rate: 1.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8437 - loss: 0.3502 - val_accuracy: 0.8652 - val_loss: 0.3269 - learning_rate: 1.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3262 - val_accuracy: 0.8652 - val_loss: 0.3248 - learning_rate: 1.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3395 - val_accuracy: 0.8629 - val_loss: 0.3269 - learning_rate: 1.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3166 - val_accuracy: 0.8652 - val_loss: 0.3227 - learning_rate: 1.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.3445 - val_accuracy: 0.8652 - val_loss: 0.3261 - learning_rate: 1.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3212 - val_accuracy: 0.8562 - val_loss: 0.3262 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3386 - val_accuracy: 0.8629 - val_loss: 0.3240 - learning_rate: 1.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3182 - val_accuracy: 0.8640 - val_loss: 0.3252 - learning_rate: 1.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8531 - loss: 0.3338 - val_accuracy: 0.8640 - val_loss: 0.3246 - learning_rate: 1.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3371 - val_accuracy: 0.8640 - val_loss: 0.3235 - learning_rate: 1.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.3342 - val_accuracy: 0.8640 - val_loss: 0.3232 - learning_rate: 1.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3218 - val_accuracy: 0.8640 - val_loss: 0.3200 - learning_rate: 1.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.3122 - val_accuracy: 0.8640 - val_loss: 0.3223 - learning_rate: 1.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3097 - val_accuracy: 0.8573 - val_loss: 0.3216 - learning_rate: 1.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.3298 - val_accuracy: 0.8640 - val_loss: 0.3226 - learning_rate: 1.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3304 - val_accuracy: 0.8640 - val_loss: 0.3190 - learning_rate: 1.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3038 - val_accuracy: 0.8640 - val_loss: 0.3240 - learning_rate: 1.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3172 - val_accuracy: 0.8629 - val_loss: 0.3206 - learning_rate: 1.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.3212 - val_accuracy: 0.8652 - val_loss: 0.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.3257 - val_accuracy: 0.8607 - val_loss: 0.3239 - learning_rate: 1.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3327 - val_accuracy: 0.8652 - val_loss: 0.3219 - learning_rate: 1.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3182 - val_accuracy: 0.8652 - val_loss: 0.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3397 - val_accuracy: 0.8652 - val_loss: 0.3229 - learning_rate: 1.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 0.3332 - val_accuracy: 0.8640 - val_loss: 0.3192 - learning_rate: 1.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3272 - val_accuracy: 0.8618 - val_loss: 0.3257 - learning_rate: 1.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3140 - val_accuracy: 0.8607 - val_loss: 0.3201 - learning_rate: 1.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.2983 - val_accuracy: 0.8607 - val_loss: 0.3190 - learning_rate: 1.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3323 - val_accuracy: 0.8562 - val_loss: 0.3210 - learning_rate: 1.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 0.3263 - val_accuracy: 0.8596 - val_loss: 0.3180 - learning_rate: 1.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.3119 - val_accuracy: 0.8573 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3287 - val_accuracy: 0.8629 - val_loss: 0.3208 - learning_rate: 1.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3156 - val_accuracy: 0.8629 - val_loss: 0.3137 - learning_rate: 1.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8680 - loss: 0.2990 - val_accuracy: 0.8618 - val_loss: 0.3119 - learning_rate: 1.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.3158 - val_accuracy: 0.8596 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3041 - val_accuracy: 0.8584 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.3308 - val_accuracy: 0.8618 - val_loss: 0.3152 - learning_rate: 1.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3086 - val_accuracy: 0.8596 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8615 - loss: 0.3194 - val_accuracy: 0.8596 - val_loss: 0.3165 - learning_rate: 1.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.2929 - val_accuracy: 0.8596 - val_loss: 0.3148 - learning_rate: 1.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.2999 - val_accuracy: 0.8584 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.3357 - val_accuracy: 0.8607 - val_loss: 0.3133 - learning_rate: 1.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 0.3024 - val_accuracy: 0.8607 - val_loss: 0.3116 - learning_rate: 1.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8761 - loss: 0.3014 - val_accuracy: 0.8596 - val_loss: 0.3104 - learning_rate: 1.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3372 - val_accuracy: 0.8629 - val_loss: 0.3092 - learning_rate: 1.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3173 - val_accuracy: 0.8607 - val_loss: 0.3146 - learning_rate: 1.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.3040 - val_accuracy: 0.8640 - val_loss: 0.3125 - learning_rate: 1.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8694 - loss: 0.3054 - val_accuracy: 0.8584 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3097 - val_accuracy: 0.8596 - val_loss: 0.3176 - learning_rate: 1.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 0.3247 - val_accuracy: 0.8618 - val_loss: 0.3124 - learning_rate: 1.0000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3122 - val_accuracy: 0.8618 - val_loss: 0.3128 - learning_rate: 1.0000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.2995 - val_accuracy: 0.8618 - val_loss: 0.3140 - learning_rate: 1.0000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.3166 - val_accuracy: 0.8618 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.3135 - val_accuracy: 0.8663 - val_loss: 0.3100 - learning_rate: 1.0000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 0.3126 - val_accuracy: 0.8652 - val_loss: 0.3137 - learning_rate: 1.0000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.2966 - val_accuracy: 0.8629 - val_loss: 0.3132 - learning_rate: 1.0000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.3107 - val_accuracy: 0.8640 - val_loss: 0.3141 - learning_rate: 1.0000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.3026 - val_accuracy: 0.8640 - val_loss: 0.3105 - learning_rate: 1.0000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.3165 - val_accuracy: 0.8629 - val_loss: 0.3156 - learning_rate: 1.0000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3066 - val_accuracy: 0.8663 - val_loss: 0.3094 - learning_rate: 1.0000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.2943 - val_accuracy: 0.8674 - val_loss: 0.3080 - learning_rate: 1.0000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3061 - val_accuracy: 0.8674 - val_loss: 0.3075 - learning_rate: 1.0000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.2969 - val_accuracy: 0.8674 - val_loss: 0.3107 - learning_rate: 1.0000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3137 - val_accuracy: 0.8674 - val_loss: 0.3112 - learning_rate: 1.0000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3012 - val_accuracy: 0.8685 - val_loss: 0.3080 - learning_rate: 1.0000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.2986 - val_accuracy: 0.8652 - val_loss: 0.3096 - learning_rate: 1.0000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3155 - val_accuracy: 0.8652 - val_loss: 0.3166 - learning_rate: 1.0000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3337 - val_accuracy: 0.8640 - val_loss: 0.3182 - learning_rate: 1.0000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3211 - val_accuracy: 0.8652 - val_loss: 0.3135 - learning_rate: 1.0000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.3029 - val_accuracy: 0.8663 - val_loss: 0.3136 - learning_rate: 1.0000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.3194 - val_accuracy: 0.8663 - val_loss: 0.3111 - learning_rate: 1.0000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.2935 - val_accuracy: 0.8663 - val_loss: 0.3112 - learning_rate: 1.0000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8736 - loss: 0.2896 - val_accuracy: 0.8674 - val_loss: 0.3094 - learning_rate: 1.0000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.2935 - val_accuracy: 0.8663 - val_loss: 0.3129 - learning_rate: 1.0000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.2998 - val_accuracy: 0.8663 - val_loss: 0.3121 - learning_rate: 1.0000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2991 - val_accuracy: 0.8685 - val_loss: 0.3114 - learning_rate: 1.0000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.3174 - val_accuracy: 0.8674 - val_loss: 0.3123 - learning_rate: 1.0000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.3118 - val_accuracy: 0.8652 - val_loss: 0.3118 - learning_rate: 1.0000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3070 - val_accuracy: 0.8663 - val_loss: 0.3079 - learning_rate: 1.0000e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.2993 - val_accuracy: 0.8663 - val_loss: 0.3096 - learning_rate: 1.0000e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8719 - loss: 0.2957 - val_accuracy: 0.8663 - val_loss: 0.3084 - learning_rate: 1.0000e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3047 - val_accuracy: 0.8663 - val_loss: 0.3092 - learning_rate: 1.0000e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.3021 - val_accuracy: 0.8663 - val_loss: 0.3094 - learning_rate: 1.0000e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.2911 - val_accuracy: 0.8685 - val_loss: 0.3068 - learning_rate: 1.0000e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.2739 - val_accuracy: 0.8663 - val_loss: 0.3111 - learning_rate: 1.0000e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3000 - val_accuracy: 0.8685 - val_loss: 0.3089 - learning_rate: 1.0000e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 0.3153 - val_accuracy: 0.8663 - val_loss: 0.3142 - learning_rate: 1.0000e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3025 - val_accuracy: 0.8674 - val_loss: 0.3105 - learning_rate: 1.0000e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.2904 - val_accuracy: 0.8685 - val_loss: 0.3034 - learning_rate: 1.0000e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.3122 - val_accuracy: 0.8697 - val_loss: 0.3055 - learning_rate: 1.0000e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2824 - val_accuracy: 0.8674 - val_loss: 0.3095 - learning_rate: 1.0000e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2961 - val_accuracy: 0.8697 - val_loss: 0.3021 - learning_rate: 1.0000e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2775 - val_accuracy: 0.8674 - val_loss: 0.3062 - learning_rate: 1.0000e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.2962 - val_accuracy: 0.8674 - val_loss: 0.3086 - learning_rate: 1.0000e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.3047 - val_accuracy: 0.8674 - val_loss: 0.3106 - learning_rate: 1.0000e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.2734 - val_accuracy: 0.8708 - val_loss: 0.3081 - learning_rate: 1.0000e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.3029 - val_accuracy: 0.8708 - val_loss: 0.3023 - learning_rate: 1.0000e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8749 - loss: 0.3012 - val_accuracy: 0.8708 - val_loss: 0.3091 - learning_rate: 1.0000e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.2828 - val_accuracy: 0.8685 - val_loss: 0.3050 - learning_rate: 1.0000e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.2971 - val_accuracy: 0.8674 - val_loss: 0.3083 - learning_rate: 1.0000e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2842 - val_accuracy: 0.8674 - val_loss: 0.3092 - learning_rate: 1.0000e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.2905 - val_accuracy: 0.8697 - val_loss: 0.3080 - learning_rate: 1.0000e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.2857 - val_accuracy: 0.8685 - val_loss: 0.3153 - learning_rate: 1.0000e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2941 - val_accuracy: 0.8674 - val_loss: 0.3094 - learning_rate: 1.0000e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.2859 - val_accuracy: 0.8674 - val_loss: 0.3135 - learning_rate: 1.0000e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3038 - val_accuracy: 0.8697 - val_loss: 0.3066 - learning_rate: 1.0000e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3084 - val_accuracy: 0.8685 - val_loss: 0.3131 - learning_rate: 1.0000e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.2883 - val_accuracy: 0.8663 - val_loss: 0.3105 - learning_rate: 1.0000e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.2980 - val_accuracy: 0.8663 - val_loss: 0.3069 - learning_rate: 1.0000e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8721 - loss: 0.2902 - val_accuracy: 0.8685 - val_loss: 0.3038 - learning_rate: 1.0000e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.2846 - val_accuracy: 0.8742 - val_loss: 0.3058 - learning_rate: 1.0000e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8744 - loss: 0.2854 - val_accuracy: 0.8708 - val_loss: 0.3072 - learning_rate: 1.0000e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3029 - val_accuracy: 0.8708 - val_loss: 0.3112 - learning_rate: 1.0000e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.2932 - val_accuracy: 0.8674 - val_loss: 0.3069 - learning_rate: 1.0000e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.2889 - val_accuracy: 0.8674 - val_loss: 0.3061 - learning_rate: 1.0000e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8775 - loss: 0.2766 - val_accuracy: 0.8663 - val_loss: 0.3093 - learning_rate: 1.0000e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.2866 - val_accuracy: 0.8685 - val_loss: 0.3057 - learning_rate: 1.0000e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.2922 - val_accuracy: 0.8697 - val_loss: 0.3043 - learning_rate: 1.0000e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.3059 - val_accuracy: 0.8708 - val_loss: 0.3114 - learning_rate: 1.0000e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3046 - val_accuracy: 0.8685 - val_loss: 0.3069 - learning_rate: 1.0000e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.2996 - val_accuracy: 0.8685 - val_loss: 0.3091 - learning_rate: 1.0000e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.2832 - val_accuracy: 0.8685 - val_loss: 0.3113 - learning_rate: 1.0000e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.2928 - val_accuracy: 0.8708 - val_loss: 0.3120 - learning_rate: 1.0000e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2683 - val_accuracy: 0.8719 - val_loss: 0.3103 - learning_rate: 1.0000e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.2813 - val_accuracy: 0.8719 - val_loss: 0.3069 - learning_rate: 1.0000e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.2877 - val_accuracy: 0.8719 - val_loss: 0.3066 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=200, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_test, Y_test), \n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6501 - loss: 0.6090 - val_accuracy: 0.8045 - val_loss: 0.4282 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4538 - val_accuracy: 0.8056 - val_loss: 0.3854 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.4203 - val_accuracy: 0.8236 - val_loss: 0.3581 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.3816 - val_accuracy: 0.8461 - val_loss: 0.3391 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.3696 - val_accuracy: 0.8483 - val_loss: 0.3277 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8284 - loss: 0.3581 - val_accuracy: 0.8517 - val_loss: 0.3222 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.3417 - val_accuracy: 0.8517 - val_loss: 0.3169 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.3483 - val_accuracy: 0.8517 - val_loss: 0.3118 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8542 - loss: 0.3253 - val_accuracy: 0.8551 - val_loss: 0.3099 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3161 - val_accuracy: 0.8629 - val_loss: 0.3073 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3208 - val_accuracy: 0.8685 - val_loss: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3450 - val_accuracy: 0.8640 - val_loss: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3352 - val_accuracy: 0.8697 - val_loss: 0.3015 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.3321 - val_accuracy: 0.8697 - val_loss: 0.2991 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8573 - loss: 0.3168 - val_accuracy: 0.8753 - val_loss: 0.2977 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3263 - val_accuracy: 0.8730 - val_loss: 0.2967 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3166 - val_accuracy: 0.8742 - val_loss: 0.2950 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3085 - val_accuracy: 0.8719 - val_loss: 0.2938 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.3064 - val_accuracy: 0.8730 - val_loss: 0.2952 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3138 - val_accuracy: 0.8820 - val_loss: 0.2929 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3122 - val_accuracy: 0.8730 - val_loss: 0.2911 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.3076 - val_accuracy: 0.8719 - val_loss: 0.2902 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.3011 - val_accuracy: 0.8764 - val_loss: 0.2892 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3151 - val_accuracy: 0.8775 - val_loss: 0.2881 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.3015 - val_accuracy: 0.8798 - val_loss: 0.2834 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8737 - loss: 0.2891 - val_accuracy: 0.8775 - val_loss: 0.2835 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.2992 - val_accuracy: 0.8742 - val_loss: 0.2817 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3096 - val_accuracy: 0.8753 - val_loss: 0.2818 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8757 - loss: 0.3013 - val_accuracy: 0.8753 - val_loss: 0.2821 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2877 - val_accuracy: 0.8753 - val_loss: 0.2815 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.2914 - val_accuracy: 0.8764 - val_loss: 0.2834 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.2864 - val_accuracy: 0.8742 - val_loss: 0.2799 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.2961 - val_accuracy: 0.8742 - val_loss: 0.2780 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8759 - loss: 0.2919 - val_accuracy: 0.8719 - val_loss: 0.2797 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.3048 - val_accuracy: 0.8730 - val_loss: 0.2801 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.2815 - val_accuracy: 0.8742 - val_loss: 0.2774 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8776 - loss: 0.2818 - val_accuracy: 0.8764 - val_loss: 0.2786 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.2900 - val_accuracy: 0.8742 - val_loss: 0.2804 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.2879 - val_accuracy: 0.8719 - val_loss: 0.2774 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3073 - val_accuracy: 0.8753 - val_loss: 0.2752 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.2951 - val_accuracy: 0.8764 - val_loss: 0.2765 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2647 - val_accuracy: 0.8775 - val_loss: 0.2762 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.2874 - val_accuracy: 0.8708 - val_loss: 0.2744 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2710 - val_accuracy: 0.8787 - val_loss: 0.2741 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2798 - val_accuracy: 0.8775 - val_loss: 0.2764 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.2960 - val_accuracy: 0.8753 - val_loss: 0.2739 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8740 - loss: 0.2851 - val_accuracy: 0.8787 - val_loss: 0.2708 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.2981 - val_accuracy: 0.8798 - val_loss: 0.2739 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.2835 - val_accuracy: 0.8820 - val_loss: 0.2716 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.2933 - val_accuracy: 0.8831 - val_loss: 0.2697 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2680 - val_accuracy: 0.8831 - val_loss: 0.2692 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.2784 - val_accuracy: 0.8831 - val_loss: 0.2704 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2707 - val_accuracy: 0.8820 - val_loss: 0.2712 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8932 - loss: 0.2514 - val_accuracy: 0.8730 - val_loss: 0.2732 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2707 - val_accuracy: 0.8820 - val_loss: 0.2717 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.2881 - val_accuracy: 0.8798 - val_loss: 0.2739 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2667 - val_accuracy: 0.8831 - val_loss: 0.2697 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2685 - val_accuracy: 0.8787 - val_loss: 0.2707 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.2798 - val_accuracy: 0.8787 - val_loss: 0.2710 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2617 - val_accuracy: 0.8798 - val_loss: 0.2703 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2556 - val_accuracy: 0.8798 - val_loss: 0.2695 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8810 - loss: 0.2689 - val_accuracy: 0.8787 - val_loss: 0.2690 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2555 - val_accuracy: 0.8809 - val_loss: 0.2695 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2691 - val_accuracy: 0.8809 - val_loss: 0.2687 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2598 - val_accuracy: 0.8809 - val_loss: 0.2683 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2604 - val_accuracy: 0.8809 - val_loss: 0.2683 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.2791 - val_accuracy: 0.8820 - val_loss: 0.2687 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2732 - val_accuracy: 0.8843 - val_loss: 0.2685 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.2762 - val_accuracy: 0.8843 - val_loss: 0.2678 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2722 - val_accuracy: 0.8843 - val_loss: 0.2677 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.2697 - val_accuracy: 0.8843 - val_loss: 0.2677 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2529 - val_accuracy: 0.8843 - val_loss: 0.2687 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2695 - val_accuracy: 0.8831 - val_loss: 0.2696 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.2868 - val_accuracy: 0.8831 - val_loss: 0.2694 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2655 - val_accuracy: 0.8787 - val_loss: 0.2701 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2756 - val_accuracy: 0.8809 - val_loss: 0.2695 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2513 - val_accuracy: 0.8787 - val_loss: 0.2695 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.2880 - val_accuracy: 0.8798 - val_loss: 0.2691 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2654 - val_accuracy: 0.8820 - val_loss: 0.2690 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.2768 - val_accuracy: 0.8820 - val_loss: 0.2689 - learning_rate: 1.2500e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2762 - val_accuracy: 0.8820 - val_loss: 0.2693 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.2630 - val_accuracy: 0.8820 - val_loss: 0.2692 - learning_rate: 1.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2705 - val_accuracy: 0.8809 - val_loss: 0.2691 - learning_rate: 1.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8989 - loss: 0.2468 - val_accuracy: 0.8831 - val_loss: 0.2689 - learning_rate: 1.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2644 - val_accuracy: 0.8831 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2619 - val_accuracy: 0.8831 - val_loss: 0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2678 - val_accuracy: 0.8809 - val_loss: 0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.2661 - val_accuracy: 0.8809 - val_loss: 0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2648 - val_accuracy: 0.8787 - val_loss: 0.2688 - learning_rate: 1.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2628 - val_accuracy: 0.8809 - val_loss: 0.2682 - learning_rate: 1.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.2686 - val_accuracy: 0.8809 - val_loss: 0.2684 - learning_rate: 1.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2525 - val_accuracy: 0.8787 - val_loss: 0.2686 - learning_rate: 1.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2685 - val_accuracy: 0.8787 - val_loss: 0.2688 - learning_rate: 1.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.2522 - val_accuracy: 0.8787 - val_loss: 0.2688 - learning_rate: 1.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2391 - val_accuracy: 0.8787 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.2652 - val_accuracy: 0.8775 - val_loss: 0.2688 - learning_rate: 1.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.2676 - val_accuracy: 0.8787 - val_loss: 0.2684 - learning_rate: 1.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.2799 - val_accuracy: 0.8787 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.2771 - val_accuracy: 0.8787 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2490 - val_accuracy: 0.8787 - val_loss: 0.2687 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "deepmodel = Sequential()\n",
    "deepmodel.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "deepmodel.add(Dropout(0.3))\n",
    "deepmodel.add(Dense(64, activation='relu'))\n",
    "deepmodel.add(Dropout(0.3))\n",
    "deepmodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "deepmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "\n",
    "\n",
    "history = deepmodel.fit(X_train, Y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_test, Y_test), \n",
    "                    callbacks=[lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
